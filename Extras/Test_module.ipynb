{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from io import StringIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# path joining version for other paths\n",
    "DIR = 'test'\n",
    "length_dir = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
    "print(length_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rtf1ansiansicpg1252cocoartf1404cocoasubrtf470'\n",
      " 'fonttblf0fswissfcharset0' 'ArialMT'\n",
      " 'colortblred255green255blue255red26green26blue26red255green255blue255'\n",
      " 'paperw11900paperh16840margl1440margr1440vieww10800viewh8400viewkind0'\n",
      " 'deftab720' 'pardpardeftab720sl220partightenfactor0' 'f0fs20' 'cf2' 'cb3'\n",
      " 'expnd0expndtw0kerning0' 'outl0strokewidth0' 'strokec2' 'Dear' 'Sir'\n",
      " 'pardpardeftab720sl220partightenfactor0' 'cf2' 'cb1'\n",
      " 'pardpardeftab720sl220partightenfactor0' 'cf2' 'cb3' 'PRML' 'quiz'\n",
      " 'first' 'exam' 'taken' 'among' 'courses' 'IIT' 'Madras' 'really' 'sure'\n",
      " 'kind' 'questions' 'expect' 'either'\n",
      " 'pardpardeftab720sl220partightenfactor0' 'cf2' 'cb1'\n",
      " 'pardpardeftab720sl220partightenfactor0' 'cf2' 'cb3' 'received' 'lot'\n",
      " 'requests' 'classmates' 'request' 'increase' 'number' 'quizzes' '6'\n",
      " 'make' 'best' '4' '6' 'raised' 'issue' 'CR' 'meeting' 'told' 'ask'\n",
      " 'pardpardeftab720sl220partightenfactor0' 'cf2' 'cb1'\n",
      " 'pardpardeftab720sl220partightenfactor0' 'cf2' 'cb3' 'would' 'really'\n",
      " 'grateful' 'could' 'consider' 'pardpardeftab720sl220partightenfactor0'\n",
      " 'cf2' 'cb1' 'pardpardeftab720sl220partightenfactor0' 'cf2' 'cb3' 'Thanks'\n",
      " 'regards']\n",
      "['rtf1ansiansicpg1252cocoartf1404cocoasubrtf470'\n",
      " 'fonttblf0fswissfcharset0' 'Helvetica'\n",
      " 'colortblred255green255blue255red53green53blue53'\n",
      " 'paperw11900paperh16840margl1440margr1440vieww10800viewh8400viewkind0'\n",
      " 'deftab560' 'pardpardeftab560slleading20partightenfactor0' 'f0fs24' 'cf2'\n",
      " 'Dear' 'Beneficiary' 'United' 'Nations' 'Compensation' 'Commission'\n",
      " 'UNCC' 'approved' 'pay' 'compensation' 'amount' 'US1500000' 'One'\n",
      " 'Million' 'Five' 'Hundred' 'Thousand' 'United' 'State' 'Dollars' 'due'\n",
      " 'losses' 'damages' 'suffered' 'delayed' 'foreign' 'contract' 'payment'\n",
      " 'individuals' 'firms' 'contractors' 'inheritance' 'nextofkin' 'super'\n",
      " 'hurricane' 'Sandy' 'lottery' 'beneficiaries' 'originated' 'Africa'\n",
      " 'Europe' 'Americas' 'Asia' 'including' 'Middle' 'East' 'approved'\n",
      " 'Compensation' 'package' 'deposited' 'Security' 'Vault' 'SunWay'\n",
      " 'Finance' 'Security' 'company' 'USA' 'waiting' 'delivery'\n",
      " 'identification' 'swift' 'delivery' 'compensation' 'package' 'advice'\n",
      " 'contact' 'Diplomat' 'Ellis' 'Gammon' 'SunWay' 'Finance' 'Security'\n",
      " 'company' 'reconfirm' 'delivery' 'details' 'call' 'Tel' '1' '321' '586'\n",
      " '1802' 'Emaila0ellisgammon8gmailcom' '1' 'Full' 'Name' '2' 'Delivery'\n",
      " 'Address' '3' 'Direct' 'Phone' 'Number' '4' 'Nearest' 'Airport' '5'\n",
      " 'AgeOccupation' 'Congratulations' 'payment' 'approval' 'faithfully' 'Mrs'\n",
      " 'Jennifer' 'Mcnichols' 'UNCC' 'Compensation' 'Coordinator']\n"
     ]
    }
   ],
   "source": [
    "#Function to Process the text data and 1. Remove Punctuation 2.Stop Words 3.Stemming\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def process_text(text):\n",
    "    no_punc = [char for char in text if char not in string.punctuation]\n",
    "    no_punc = ''.join(no_punc)\n",
    "    return ' '.join([word for word in no_punc.split() if word.lower() not in stopwords.words('english')])\n",
    "\n",
    "\n",
    "name = \"email\"\n",
    "ext = \".txt\"\n",
    "for i in range(length_dir-1):\n",
    "    f_name = DIR+\"/\"+name+str(i+1)+ext\n",
    "    f = open(f_name, \"r\")\n",
    "    f_data = f.read()\n",
    "    f_data=process_text(f_data)\n",
    "    #print(abc)\n",
    "    tokens = word_tokenize(f_data)\n",
    "    arr = np.array(tokens)\n",
    "    print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
